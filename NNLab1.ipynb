{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPGqror5BMe92i3iZErWCHd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nyannnyan/ColabData/blob/main/NNLab1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zArRFyvDcKBl",
        "outputId": "9977c4e2-1f9d-416d-b531-def3348cf344"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 1]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# ANDの入力と出力\n",
        "X = [[0., 0.], [0., 1.], [1., 0.], [1., 1.]]\n",
        "y = [0, 0, 0, 1]\n",
        "\n",
        "# 隠れ層なし、線形活性化関数、lbfgsソルバー\n",
        "clf = MLPClassifier(hidden_layer_sizes=(), activation='identity', solver='lbfgs')\n",
        "clf.fit(X, y)\n",
        "\n",
        "# 予測を確認\n",
        "print(clf.predict(X))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ORの入力と出力\n",
        "X = [[0., 0.], [0., 1.], [1., 0.], [1., 1.]]\n",
        "y = [0, 1, 1, 1]\n",
        "\n",
        "# 隠れ層なし、線形活性化関数、lbfgsソルバー\n",
        "clf = MLPClassifier(hidden_layer_sizes=(), activation='identity', solver='lbfgs')\n",
        "clf.fit(X, y)\n",
        "\n",
        "# 予測を確認\n",
        "print(clf.predict(X))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKx7ovUbcV2b",
        "outputId": "85f261e3-ff5a-4799-89c4-21b6bde0a5cd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# XORの入力と出力\n",
        "X = [[0., 0.], [0., 1.], [1., 0.], [1., 1.]]\n",
        "y = [0, 1, 1, 0]\n",
        "\n",
        "# 隠れ層なし、線形活性化関数、lbfgsソルバー\n",
        "clf = MLPClassifier(hidden_layer_sizes=(), activation='identity', solver='lbfgs')\n",
        "clf.fit(X, y)\n",
        "\n",
        "# 予測を確認\n",
        "print(clf.predict(X))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aT7d2NT0cZ6o",
        "outputId": "493897ec-aede-4de4-cb5e-8b5a93f5cb7d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf = MLPClassifier(hidden_layer_sizes=(4, 2), activation='identity', solver='lbfgs')\n",
        "clf.fit(X, y)\n",
        "\n",
        "print(clf.predict(X))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RLiwkJVccIO",
        "outputId": "e0bde90f-42ef-4a6f-e737-395d5eef7e9d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "clf = MLPClassifier(hidden_layer_sizes=(4, 2), activation='tanh', solver='lbfgs', max_iter=1000)\n",
        "\n",
        "for i in range(10):\n",
        "    clf.fit(X, y)\n",
        "    print(f\"試行{i}: 予測値 = {clf.predict(X)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WughJ2cZcf-C",
        "outputId": "8d3ed486-8824-4fdb-9083-7a086af1e47d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "試行0: 予測値 = [0 1 1 0]\n",
            "試行1: 予測値 = [0 1 1 0]\n",
            "試行2: 予測値 = [0 1 1 0]\n",
            "試行3: 予測値 = [0 1 1 0]\n",
            "試行4: 予測値 = [0 1 1 0]\n",
            "試行5: 予測値 = [0 1 1 0]\n",
            "試行6: 予測値 = [0 1 1 0]\n",
            "試行7: 予測値 = [0 1 1 0]\n",
            "試行8: 予測値 = [0 1 1 0]\n",
            "試行9: 予測値 = [0 1 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "dataset = load_digits()\n",
        "X = dataset.data\n",
        "y = dataset.target\n",
        "\n",
        "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.1)\n",
        "\n",
        "# 隠れ層2つ(50ノード、20ノード)、relu活性化関数、adamソルバー\n",
        "clf = MLPClassifier(hidden_layer_sizes=(50, 20), activation='relu', solver='adam', max_iter=500)\n",
        "clf.fit(train_X, train_y)\n",
        "\n",
        "test_y_pred = clf.predict(test_X)\n",
        "acc = accuracy_score(test_y, test_y_pred)\n",
        "print(f\"テストデータに対する正解率: {acc*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qsMGA8JcjDc",
        "outputId": "b6a2e14a-ce2b-4ec0-cb33-8699a6afe7e2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "テストデータに対する正解率: 96.11%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision  # Install PyTorch and torchvision if not already installed\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9k0vUZVadhL7",
        "outputId": "50489759-138f-49af-b909-c5228ad24ed0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "jNOOCWwKdmNr"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNet5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet5, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)  # Input channels: 1 (grayscale), Output channels: 6, Kernel size: 5\n",
        "        self.pool = nn.MaxPool2d(2, 2)  # Pooling size: 2x2\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)  # Input channels: 6, Output channels: 16, Kernel size: 5\n",
        "        self.fc1 = nn.Linear(16 * 4 * 4, 120)  # Fully connected layer 1, Input features: 16 * 4 * 4 (from conv2 output), Output features: 120\n",
        "        self.fc2 = nn.Linear(120, 84)  # Fully connected layer 2, Input features: 120, Output features: 84\n",
        "        self.fc3 = nn.Linear(84, 10)  # Fully connected layer 3 (output layer), Input features: 84, Output features: 10 (number of classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))  # ReLU activation after conv1, then pooling\n",
        "        x = self.pool(F.relu(self.conv2(x)))  # ReLU activation after conv2, then pooling\n",
        "        x = x.view(-1, 16 * 4 * 4)  # Flatten for fully connected layers\n",
        "        x = F.relu(self.fc1(x))  # ReLU activation for fc1\n",
        "        x = F.relu(self.fc2(x))  # ReLU activation for fc2\n",
        "        x = self.fc3(x)  # Output layer without activation (assuming softmax in loss function)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "dae3k9ggergQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "epochs = 10\n",
        "\n",
        "# Download and transform MNIST dataset\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
        "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n",
        "\n",
        "# Data loaders\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Create the model, optimizer, and loss function\n",
        "model = LeNet5()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data\n"
      ],
      "metadata": {
        "id": "ttWZz83veuIr"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZS73H0qEgi9a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}